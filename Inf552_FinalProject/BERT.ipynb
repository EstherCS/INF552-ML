{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgL3dm9JPr0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers tqdm boto3 requests regex -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7Abfr2SPyVi",
        "colab_type": "code",
        "outputId": "5cf1d890-f051-49df-f2cd-35c2a12fc384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# BERT-BASE model, all words are lowercase\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-uncased\"  \n",
        "\n",
        "# get the tokenizer of this model\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "\n",
        "clear_output()\n",
        "print(\"PyTorch version: \", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version:  1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvZlmi6YQUNV",
        "colab_type": "code",
        "outputId": "24ac842e-de1d-4853-bc50-957ff0277a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# connect to google drive to get the data\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/train.csv', index_col=0)\n",
        "train.to_csv(\"train.tsv\", sep = \"\\t\", index = False)\n",
        "train.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cb774db0d1</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549e992a42</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>088c60f138</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  ... sentiment\n",
              "textID                                                      ...          \n",
              "cb774db0d1             I`d have responded, if I were going  ...   neutral\n",
              "549e992a42   Sooo SAD I will miss you here in San Diego!!!  ...  negative\n",
              "088c60f138                       my boss is bullying me...  ...  negative\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66trRI3cQ3P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete the empty data\n",
        "empty_title = ((train['text'].isnull()) | (train['selected_text'].isnull()))\n",
        "df_train = train[~empty_title]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEclKiR1Q9tI",
        "colab_type": "code",
        "outputId": "37b7e60c-b7c7-4e48-b599-490d820a404a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# see all the sentiment percent in the data\n",
        "df_train.sentiment.value_counts() / len(df_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     0.404549\n",
              "positive    0.312300\n",
              "negative    0.283151\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efXOTTLxRA3W",
        "colab_type": "code",
        "outputId": "174b3ecf-c0eb-4576-d678-beaaed124494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/test.csv')\n",
        "df_test = df_test.loc[:, [\"text\", \"sentiment\"]]\n",
        "df_test.columns = [\"text\", \"label\"]\n",
        "df_test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"number of test data：\", len(df_test))\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of test data： 3534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     label\n",
              "0  Last session of the day  http://twitpic.com/67ezh   neutral\n",
              "1   Shanghai is also really exciting (precisely -...  positive\n",
              "2  Recession hit Veronique Branquinho, she has to...  negative\n",
              "3                                        happy bday!  positive\n",
              "4             http://twitpic.com/4w75p - I like it!!  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ksz5IF1RMn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        " \n",
        "class Dataset(Dataset):\n",
        "    # read tsv file and initial variables\n",
        "    def __init__(self, mode, tokenizer):\n",
        "        assert mode in [\"Mytrain\", \"Mytest\"]  \n",
        "        self.mode = mode\n",
        "        # iterator = True while trainging the Big data\n",
        "        self.df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/\" + mode + \".tsv\", sep = \"\\t\").fillna(\"\")\n",
        "        self.len = len(self.df)\n",
        "        self.label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "        # use BERT tokenizer\n",
        "        self.tokenizer = tokenizer  \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.df.iloc[idx, :].values\n",
        "        label_id = self.label_map[label]\n",
        "        label_tensor = torch.tensor(label_id)\n",
        "            \n",
        "        # create BERT tokens [CLS] of sentence and add the separation sign [SEP]\n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens_a = self.tokenizer.tokenize(text)\n",
        "        word_pieces += tokens_a + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        # convert tokens to ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "        tokens_tensor = torch.tensor(ids)\n",
        "\n",
        "        return (tokens_tensor, label_tensor)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    \n",
        "# initial a Dataset to read training data\n",
        "trainset = Dataset(\"Mytrain\", tokenizer=tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uav_AbhReqC",
        "colab_type": "code",
        "outputId": "dfe17521-e1e3-4b43-872b-272c5d2e80c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "sample_idx = 0\n",
        "\n",
        "# compare to the original data\n",
        "text, label = trainset.df.iloc[sample_idx].values\n",
        "\n",
        "# get the id tensors from Dataset\n",
        "tokens_tensor, label_tensor = trainset[sample_idx]\n",
        "\n",
        "# convert tokens_tensor to original words\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
        "combined_text = \" \".join(tokens)\n",
        "\n",
        "print(f\"\"\"[original sentence]\n",
        "sentence：{text}\n",
        "label  ：{label}\n",
        "--------------------\n",
        "[tensors from Dataset]\n",
        "tokens_tensor  ：{tokens_tensor}\n",
        "label_tensor   ：{label_tensor}\n",
        "--------------------\n",
        "[convert tokens_tensors to original words]\n",
        "{combined_text}\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[original sentence]\n",
            "sentence： I`d have responded, if I were going\n",
            "label  ：neutral\n",
            "--------------------\n",
            "[tensors from Dataset]\n",
            "tokens_tensor  ：tensor([ 101, 1045, 1036, 1040, 2031, 5838, 1010, 2065, 1045, 2020, 2183,  102])\n",
            "label_tensor   ：1\n",
            "--------------------\n",
            "[convert tokens_tensors to original words]\n",
            "[CLS] i ` d have responded , if i were going [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rftpquZ0TAup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# input of this function (samples) is a list, it contain 2 tensors return from Dataset\n",
        "# tokens_tensors : (batch_size, max_seq_len_in_batch) & label_ids : (batch_size)\n",
        "def create_mini_batch(samples):\n",
        "    tokens_tensors = [s[0] for s in samples]\n",
        "    \n",
        "    if samples[0][1] is not None:\n",
        "        label_ids = torch.stack([s[1] for s in samples])\n",
        "    else:\n",
        "        label_ids = None\n",
        "    \n",
        "    # zero pad to the same size\n",
        "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
        "    \n",
        "    # attention masks: set the value to 1 if tokens_tensors is not zero padding\n",
        "    # so BERT can just pay attention to those non-zero tokens\n",
        "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
        "    \n",
        "    # return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
        "    return tokens_tensors, masks_tensors, label_ids\n",
        "\n",
        "\n",
        "# initial a 32 batch size DataLoader\n",
        "# use \"collate_fn\" to combine list of samples to a mini-batch\n",
        "BATCH_SIZE = 32\n",
        "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, collate_fn = create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWenABVGTEmh",
        "colab_type": "code",
        "outputId": "486b53d1-a2b7-4d26-d049-16cf345c762d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "data = next(iter(trainloader))\n",
        "\n",
        "tokens_tensors, masks_tensors, label_ids = data\n",
        "\n",
        "print(f\"\"\"\n",
        "tokens_tensors.shape = {tokens_tensors.shape} \n",
        "{tokens_tensors}\n",
        "------------------------\n",
        "masks_tensors.shape  = {masks_tensors.shape}\n",
        "{masks_tensors}\n",
        "------------------------\n",
        "label_ids.shape      = {label_ids.shape}\n",
        "{label_ids}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens_tensors.shape = torch.Size([32, 51]) \n",
            "tensor([[  101,  1045,  1036,  ...,     0,     0,     0],\n",
            "        [  101, 17111,  2080,  ...,     0,     0,     0],\n",
            "        [  101,  2026,  5795,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2253,  2000,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  1036,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  3246,  ...,     0,     0,     0]])\n",
            "------------------------\n",
            "masks_tensors.shape  = torch.Size([32, 51])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "------------------------\n",
            "label_ids.shape      = torch.Size([32])\n",
            "tensor([1, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 1, 1,\n",
            "        1, 2, 0, 0, 2, 0, 2, 2])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaXIaDidTJnq",
        "colab_type": "code",
        "outputId": "f8c9fb3d-d980-473b-8c6e-57f8dfa921e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
        "NUM_LABELS = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels = NUM_LABELS)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# show modules in this model\n",
        "print(\"\"\"\n",
        "name            module\n",
        "----------------------\"\"\")\n",
        "for name, module in model.named_children():\n",
        "    if name == \"bert\":\n",
        "        for n, _ in module.named_children():\n",
        "            print(f\"{name}:{n}\")\n",
        "    else:\n",
        "        print(\"{:15} {}\".format(name, module))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "name            module\n",
            "----------------------\n",
            "bert:embeddings\n",
            "bert:encoder\n",
            "bert:pooler\n",
            "dropout         Dropout(p=0.1, inplace=False)\n",
            "classifier      Linear(in_features=768, out_features=3, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzL6MO5YTOaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(model, dataloader):\n",
        "    predictions = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            # put all tensors on GPU \n",
        "            if next(model.parameters()).is_cuda:\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "            \n",
        "            # put the two tensors and their parameter names in the model\n",
        "            tokens_tensors, masks_tensors = data[:2]\n",
        "            outputs = model(input_ids = tokens_tensors, attention_mask = masks_tensors)\n",
        "            \n",
        "            logits = outputs[0]\n",
        "            _, pred = torch.max(logits.data, 1)\n",
        "            \n",
        "            # calculate the accuracy of our classification\n",
        "            labels = data[2]\n",
        "            total += labels.size(0)\n",
        "            correct += (pred == labels).sum().item()\n",
        "                \n",
        "            # record the current batch\n",
        "            if predictions is None:\n",
        "                predictions = pred\n",
        "            else:\n",
        "                predictions = torch.cat((predictions, pred))\n",
        "    acc = correct / total\n",
        "    return predictions, acc\n",
        "    \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wxd3uHMUl-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_learnable_params(module):\n",
        "    return [p for p in module.parameters() if p.requires_grad]\n",
        "     \n",
        "model_params = get_learnable_params(model)\n",
        "clf_params = get_learnable_params(model.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_tcuCtmUsrF",
        "colab_type": "code",
        "outputId": "d79f4717-97c8-4b4e-cd38-983c4d8dede0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# start training\n",
        "model.train()\n",
        "\n",
        "# use Adam Optim to update all the parameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
        "\n",
        "EPOCHS = 10 \n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        \n",
        "        tokens_tensors, masks_tensors, labels = [t.to(device) for t in data]\n",
        "\n",
        "        # zero the parameters gradient\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids = tokens_tensors, attention_mask = masks_tensors, labels = labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # record the current batch loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # calculate the accuracy\n",
        "    predictions, acc = get_predictions(model, trainloader)\n",
        "\n",
        "    print('[epoch %d] loss: %.3f, acc: %.3f' % (epoch + 1, running_loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1] loss: 532.257, acc: 0.814\n",
            "[epoch 2] loss: 389.787, acc: 0.847\n",
            "[epoch 3] loss: 316.021, acc: 0.889\n",
            "[epoch 4] loss: 240.471, acc: 0.922\n",
            "[epoch 5] loss: 173.932, acc: 0.929\n",
            "[epoch 6] loss: 127.552, acc: 0.951\n",
            "[epoch 7] loss: 99.833, acc: 0.962\n",
            "[epoch 8] loss: 79.566, acc: 0.960\n",
            "[epoch 9] loss: 65.384, acc: 0.974\n",
            "[epoch 10] loss: 54.432, acc: 0.982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzq4tLoLu0h2",
        "colab_type": "code",
        "outputId": "3c0176f3-5db5-4cfa-ef15-16c4e3925096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "testset = Dataset(\"Mytest\", tokenizer = tokenizer)\n",
        "testloader = DataLoader(testset, batch_size = 512, collate_fn = create_mini_batch)\n",
        "\n",
        "# test the accuracy of test data\n",
        "predictions, acc = get_predictions(model, testloader)\n",
        "print('acc: ' , acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc:  0.7866440294284097\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}